{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc677d0-e5a9-4a78-ba4c-21a203c12237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import Image as Image2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoModelForObjectDetection\n",
    "from transformers import AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0a8520-cda5-4cac-91b1-27c233990a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dir = 'examples/'\n",
    "example_imges = os.listdir(example_dir)\n",
    "def extractCoords(width, height, box, add_size=2):\n",
    "    x, y, x2, y2 = tuple(box)\n",
    "    xs = np.sort([x, x2])\n",
    "    ys = np.sort([y, y2])\n",
    "    x = np.floor(xs[0])-add_size\n",
    "    x2 = np.ceil(xs[1])+add_size\n",
    "    y = np.floor(ys[0])-add_size\n",
    "    y2 = np.ceil(ys[1])+add_size\n",
    "    if x < 0:\n",
    "        x = 0\n",
    "    if y<0:\n",
    "        y = 0\n",
    "    if x2>width:\n",
    "        x2 = width\n",
    "    if y2>height:\n",
    "        y2 = height\n",
    "    return (x, y, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cc157a-0599-442a-ade0-806f531562a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "mdl_name = 'detr-resnet-50_finetuned_pkr/checkpoint-10648/'\n",
    "image_processor = AutoImageProcessor.from_pretrained(mdl_name)\n",
    "model = AutoModelForObjectDetection.from_pretrained(mdl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33abb4d3-9531-4e22-b9b8-3c94431d4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_out_dir = 'out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239d4d5a-c50f-47f8-9f31-e10c06b54112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing examples/im_1.JPEG\n",
      "Detected pk_range with confidence 0.999 at location [40.93, 52.5, 229.22, 241.54]\n",
      "Processing examples/im_9.png\n",
      "Detected pk_range with confidence 0.999 at location [85.94, 293.17, 820.85, 744.1]\n",
      "Processing examples/im_7.PNG\n",
      "Detected pk_range with confidence 1.0 at location [7.74, 48.08, 410.35, 455.0]\n",
      "Processing examples/im_6.JPEG\n",
      "Detected pk_range with confidence 1.0 at location [0.32, 1.26, 407.2, 407.31]\n",
      "Processing examples/im_10.png\n",
      "Detected pk_range with confidence 0.999 at location [101.55, 294.03, 839.68, 743.97]\n",
      "Processing examples/im_0.JPEG\n",
      "Detected pk_range with confidence 1.0 at location [103.32, 5.91, 371.01, 261.99]\n",
      "Processing examples/im_5.JPEG\n",
      "Detected pk_range with confidence 0.999 at location [31.03, 574.96, 356.76, 898.55]\n",
      "Detected pk_range with confidence 0.998 at location [992.68, 575.91, 1299.91, 887.03]\n",
      "Detected pk_range with confidence 0.996 at location [378.41, 134.63, 683.32, 446.41]\n",
      "Detected pk_range with confidence 0.998 at location [364.43, 578.22, 669.53, 889.03]\n",
      "Detected pk_range with confidence 0.997 at location [57.35, 134.68, 364.54, 449.56]\n",
      "Detected pk_range with confidence 0.992 at location [1007.01, 135.73, 1307.24, 445.78]\n",
      "Detected pk_range with confidence 0.995 at location [689.93, 135.13, 1001.19, 447.09]\n",
      "Detected pk_range with confidence 0.999 at location [678.14, 576.1, 987.19, 885.78]\n",
      "Processing examples/im_4.JPEG\n",
      "Detected pk_range with confidence 1.0 at location [0.39, 0.16, 719.49, 718.83]\n",
      "Processing examples/im_8.PNG\n",
      "Detected pk_range with confidence 1.0 at location [0.32, 1.06, 1200.51, 716.45]\n",
      "Processing examples/im_3.PNG\n",
      "Detected pk_range with confidence 1.0 at location [6.34, 41.89, 738.63, 771.54]\n",
      "Processing examples/im_2.PNG\n",
      "Detected pk_range with confidence 0.999 at location [-1.69, 116.44, 682.86, 725.18]\n"
     ]
    }
   ],
   "source": [
    "img_out_ind = 0\n",
    "for ii in range(0, len(example_imges)):\n",
    "    fn = f'{example_dir}{example_imges[ii]}'\n",
    "    print(f'Processing {fn}')\n",
    "    image = Image.open(fn)\n",
    "    \n",
    "    fix = Image.new(\"RGB\", image.size, (255, 255, 255)) # remove transparency if needed\n",
    "    fix.paste(image) # 3 is the alpha channel\n",
    "    image = fix\n",
    "    width, height = image.size\n",
    "    with torch.no_grad():\n",
    "        inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        target_sizes = torch.tensor([image.size[::-1]])\n",
    "        results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
    "    \n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "        )\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        x, y, x2, y2 = tuple(box)\n",
    "        crop_coords = extractCoords(width, height, box)\n",
    "        c_range = image.crop(crop_coords).save(f'{example_out_dir}{img_out_ind}.png')\n",
    "        img_out_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e5bfb6-7227-4e1b-8d06-48e925278e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
